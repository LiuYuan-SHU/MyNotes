[TOC]

> 对于网页的节点来说，可以定义`id`、`class`等其他属性，而且节点之间还有层次关系。我们其实可以使用XPath或者CSS选择器来定位一个或多个节点，并且调用相应的方法来获取这个节点的内容或者属性，就可以得到目标信息。

# 1. XPath概览

XPath提供了非常简洁明了的路径选择方式

# 2. XPath常用规则

| 表达式     | 描述                     |
| ---------- | ------------------------ |
| `nodename` | 选取此节点的所有子节点   |
| `/`        | 从当前节点选取直接子节点 |
| `//`       | 从当前节点选取子孙节点   |
| `.`        | 选取当前节点             |
| `..`       | 选取当前节点的父节点     |
| `@`        | 选取属性                 |

# 3. 准备工作

> `pip install lxml`

# 4. 实例引入

[3.1.1_实例引入.py](https://github.com/LiuYuan-SHU/MyNotes/blob/e8b1b6cbee2510592c5a22e51827b46abc7e12bd/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/%E7%AC%AC%E4%B8%89%E7%AB%A0/3.1/3.1.1_%E5%AE%9E%E4%BE%8B%E5%BC%95%E5%85%A5.py)

我们在实例中声明了一段HTML文本，接着调用`HTML`类进行初始化，这样就成功构造了一个XPath解析对象。需要注意的是，实例中HTML文本中的最后一个`li`节点是没有闭合的，而`etree`模块可以自动修正HTML文本。

![](第三章——网页数据的解析提取.assets/Pasted%20image%2020220717152328.png)

之后调用`tostring`方法即可输出修正后的HTML代码，但是结果是`bytes`类型。于是利用`decode`方法将其转化成`str`类型。

******

当然，我们也可以不声明，直接读取文本文件进行解析。假设我们有一个HTML文件`test.html`，我们可以使用这样的方法来进行解析：

```python
from lxml import etree

html = etree.parse('./test.html', etree.HTMLParser())
result = etree.tostring(html)
print(result.decode('utf-8'))
```

# 5. 所有节点

[3.1.2_所有节点.py](https://github.com/LiuYuan-SHU/MyNotes/blob/a3b57fd85ffac92a507b641cf841643443b546c7/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/%E7%AC%AC%E4%B8%89%E7%AB%A0/3.1/3.1.2_%E6%89%80%E6%9C%89%E8%8A%82%E7%82%B9.py)

我们一般会以`//`开头的XPath规则来选取所有符合要求的节点。