[TOC]

# 2.1 urllibçš„ä½¿ç”¨

> `pip install urllib3`

## urllibçš„åŸºæœ¬ä½¿ç”¨

[2.1.0_urllibçš„åŸºæœ¬ä½¿ç”¨.py](https://github.com/LiuYuan-SHU/MyNotes/blob/master/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/2_use_of_basic_libraries/2.1/2.1.0_urllib%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8.py)

### urlopenå‚æ•°è¯¦è§£

[2.1.1_urlopenå‚æ•°è¯¦è§£.py](https://github.com/LiuYuan-SHU/MyNotes/blob/master/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/2_use_of_basic_libraries/2.1/2.1.1_urlopen%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3.py)

## Request

[2.1.2_Request.py](https://github.com/LiuYuan-SHU/MyNotes/blob/master/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/2_use_of_basic_libraries/2.1/2.1.2_urllib.request.py)

> å¦‚æœéœ€è¦å¾€è¯·æ±‚ä¸­åŠ å…¥Headersç­‰ä¿¡æ¯ï¼Œå°±éœ€è¦Requestç±»æ¥æ„å»ºè¯·æ±‚

### Requestç±»

å¦‚æœéœ€è¦å¾€è¯·æ±‚ä¸­åŠ å…¥Headersç­‰ä¿¡æ¯ï¼Œå°±éœ€è¦Requestç±»æ¥æ„å»ºè¯·æ±‚ã€‚é€šè¿‡ç‹¬ç«‹æ„é€ Requestå¯¹è±¡ï¼Œæˆ‘ä»¬å¯ä»¥ï¼š

1. å°†è¯·æ±‚ç‹¬ç«‹ç”Ÿæˆæˆä¸€ä¸ªå¯¹è±¡
2. æ›´åŠ ä¸°å¯Œå’Œçµæ´»åœ°é…ç½®å‚æ•°

åŒæ—¶ï¼Œæˆ‘ä»¬åœ¨ä½¿ç”¨`urlopen`æ–¹æ³•çš„æ—¶å€™ï¼Œä¹Ÿå¯ä»¥ç›´æ¥ä¼ é€’ä¸€ä¸ª`Request`å¯¹è±¡ä½œä¸ºå‚æ•°ã€‚

---

```python
def __init__(self,
             url: str,
             data: bytes | None = ...,
             headers: MutableMapping[str, str] = ...,
             origin_req_host: str | None = ...,
             unverifiable: bool = ...,
             method: str | None = ...)
```

1. urlï¼šç”¨äºè¯·æ±‚URLï¼Œå¿…ä¼ å‚æ•°ï¼Œå…¶ä½™éƒ½æ˜¯å¯é€‰å‚æ•°
2. dataï¼šæ•°æ®å¿…é¡»æ˜¯`bytes`ç±»å‹ã€‚å¦‚æœæ•°æ®æ˜¯å­—å…¸ï¼Œå¯ä»¥å…ˆç”¨`urllib.parse.urlencode`æ–¹æ³•è¿›è¡Œå¤„ç†
3. headersï¼šè¯·æ±‚å¤´ã€‚å¯ä»¥ç›´æ¥åœ¨æ­¤å¤„è¿›è¡Œæ„é€ ï¼Œä¹Ÿå¯ä»¥é€šè¿‡è°ƒç”¨è¿”å›çš„å®ä¾‹çš„`add_header`æ–¹æ³•æ·»åŠ 
   
    æ·»åŠ è¯·æ±‚å¤´æœ€å¸¸è§çš„æ–¹æ³•å°±æ˜¯é€šè¿‡ä¿®æ”¹`User-Agent`æ¥ä¼ªè£…æµè§ˆå™¨ã€‚é»˜è®¤çš„`User-Agent`æ˜¯`Python-urllib`ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™æ ·çš„æ–¹å¼ä¼ªè£…æˆç«ç‹æµè§ˆå™¨ï¼š
    
    ```
    Mozilla/5.0 (X11; U; Linux i686) Gecko/20071127 FireFox/2.0.0.11
    ```
    
4. origin_req_hostï¼šè¯·æ±‚æ–¹çš„hoståç§°æˆ–IPåœ°å€
5. unverifiableï¼šè¯·æ±‚æ˜¯å¦æ˜¯æ— æ³•éªŒè¯çš„ï¼Œé»˜è®¤å€¼falseã€‚æ„æ€æ˜¯ç”¨æˆ·æ˜¯å¦æœ‰èµ„æ ¼è·å–è¯·æ±‚çš„ç»“æœã€‚
6. methodï¼šæŒ‡ç¤ºè¯·æ±‚ä½¿ç”¨çš„æ–¹æ³•ï¼Œä¾‹å¦‚GET,POST,PUTç­‰

---

### å‡½æ•°`multi_parameter_request`ï¼ˆè§æ–‡ä»¶2.1.2ï¼‰

æˆ‘ä»¬åœ¨`url`ä¸­è®¾ç½®URLï¼Œåœ¨`headers`ä¸­è®¾ç½®äº†`User-Agent`å’Œ`Host`ï¼Œä»è€Œä¼ªè£…äº†è‡ªå·±çš„æµè§ˆå™¨èº«ä»½è¿˜æœ‰IPåœ°å€

æˆ‘ä»¬å°†`name`æ”¾åœ¨å­—å…¸ä¸­ï¼Œå¹¶ä½¿ç”¨`urlencode`æ–¹æ³•è¿›è¡Œå¤„ç†ï¼Œæœ€åå¤„ç†æˆ`bytes`ç±»å‹ï¼Œå°†ä¸‰ä¸ªå‚æ•°ç”¨äºæ„é€ ä¸€ä¸ª`Request`å¯¹è±¡

```json
{
  "args": {}, 
  "data": "", 
  "files": {}, 
  "form": {
    "name": "germey"
  }, 
  "headers": {
    "Accept-Encoding": "identity", 
    "Content-Length": "11", 
    "Content-Type": "application/x-www-form-urlencoded", 
    "Host": "www.httpbin.org", 
    "User-Agent": "Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)", 
    "X-Amzn-Trace-Id": "Root=1-62b87ba7-0b48d956616b76aa2aa845c0"
  }, 
  "json": null, 
  "origin": "199.101.192.143", 
  "url": "https://www.httpbin.org/post"
}
```

å¯ä»¥çœ‹åˆ°ï¼Œ`form`ä¸­å­˜æ”¾ç€æˆ‘ä»¬çš„`data`ï¼Œè€Œåœ¨å“åº”å¤´ä¸­ï¼Œæˆ‘ä»¬çš„è¯†åˆ«å’ŒHoståœ°å€éƒ½å·²ç»æ”¹å˜

## é«˜çº§ç”¨æ³•

> å¦‚æœæƒ³è¦è¿›ä¸€æ­¥æ“ä½œCookieï¼Œæˆ–è€…æ˜¯ä»£ç†ï¼Œå°±éœ€è¦æ›´ä¸ºå¼ºå¤§çš„å·¥å…·ã€‚
> 

### Handlerå’ŒOpener

> Handlerï¼ˆ`urllib.request.BaseHandler`æ˜¯å…¶ä»–æ‰€æœ‰Handlerç±»çš„çˆ¶ç±»ï¼‰å¯ä»¥ç†è§£ä¸ºå„ç§å¤„ç†å™¨ï¼Œå¯ä»¥ä¸“é—¨ç”¨äºå¤„ç†ç™»å½•éªŒè¯ã€Cookieå’Œä»£ç†ç­‰
> 
> 
> Openerï¼ˆ`OpennerDirector`ï¼‰ï¼Œ`urlopen`å…¶å®å°±æ˜¯`urllib`æä¾›çš„ä¸€ä¸ª`Openner`ã€‚
> 

ä¹‹å‰ä½¿ç”¨çš„`Request`ç±»å’Œ`urlopen`ç±»æ˜¯å·²ç»è¢«å°è£…å¥½çš„æå…¶å¸¸ç”¨çš„è¯·æ±‚æ–¹æ³•ï¼Œä½†å½“æˆ‘ä»¬éœ€è¦æ›´é«˜çº§çš„åŠŸèƒ½çš„æ—¶å€™ï¼Œå°±éœ€è¦æ›´åº•å±‚çš„äº‹ä¾‹æ¥å®Œæˆæ“ä½œã€‚

### éªŒè¯

[2.1.3_éªŒè¯.py](https://github.com/LiuYuan-SHU/MyNotes/blob/master/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/2_use_of_basic_libraries/2.1/2.1.3_%E9%AA%8C%E8%AF%81.py)

![[Python3ç½‘ç»œçˆ¬è™«å¼€å‘å®æˆ˜.assets/ç™»å½•.png]]

[https://ssr3.scrape.center/](https://ssr3.scrape.center/)

é‡åˆ°äº†è¿™ç§æƒ…å†µï¼Œå°±è¡¨ç¤ºè¿™ä¸ªç½‘ç«™å¯ç”¨äº†åŸºæœ¬èº«ä»½è®¤è¯ï¼ˆ**HTTP Basic Access Authentication**ï¼‰ï¼Œè¿™æ˜¯ä¸€ç§ç™»å½•éªŒè¯æ–¹å¼ï¼Œå…è®¸ç½‘é¡µæµè§ˆå™¨æˆ–å…¶ä»–å®¢æˆ·ç«¯ç¨‹åºåœ¨è¯·æ±‚ç½‘ç«™æ—¶æä¾›ç”¨æˆ·åå’Œå£ä»¤å½¢å¼çš„èº«ä»½éªŒè¯ã€‚

1. é¦–å…ˆï¼Œæˆ‘ä»¬å®ä¾‹åŒ–ä¸€ä¸ª`HTTPPasswordMgrWithDefaultRealm`å¯¹è±¡ï¼Œå¹¶åˆ©ç”¨`add_password`æ–¹æ³•æ·»åŠ ç”¨æˆ·åå’Œå¯†ç 
2. æ¥ç€ï¼Œæˆ‘ä»¬ç”¨æ­¥éª¤1ä¸­å®ä¾‹åŒ–çš„å¯¹è±¡ä½œä¸º`HTTPBasicAuthHandler`å¯¹è±¡çš„æ„é€ å‡½æ•°å‚æ•°ï¼Œè¿™æ ·å°±æ„å»ºäº†ä¸€ä¸ªç”¨æ¥å¤„ç†éªŒè¯çš„Handlerç±»
3. ç„¶ååˆ©ç”¨`Openner`ç±»çš„`open`æ–¹æ³•æ‰“å¼€é“¾æ¥ï¼Œå³å¯å®ŒæˆéªŒè¯

### ä»£ç†

[2.1.4_ä»£ç†.py](https://github.com/LiuYuan-SHU/MyNotes/blob/master/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/2_use_of_basic_libraries/2.1/2.1.4_%E4%BB%A3%E7%90%86.py)

åŸç†ä¸[éªŒè¯](https://www.notion.so/2-1-urllib-bc54585a643148838747b320d9a1aaa4)ç›¸åŒï¼Œå”¯ä¸€éœ€è¦æ³¨æ„çš„åœ°æ–¹åœ¨äºï¼Œè¿™é‡Œç”¨çš„æ˜¯æœ¬åœ°ä»£ç†ï¼Œå¦‚æœæœ¬åœ°çš„ç›¸åº”ç«¯å£æ²¡æœ‰è®¾ç½®HTTPä»£ç†ï¼Œé‚£ä¹ˆå°±ä¼šå‡ºç°è¿™æ ·çš„æŠ¥é”™ç»“æœï¼š

![[Python3ç½‘ç»œçˆ¬è™«å¼€å‘å®æˆ˜.assets/æœªåœ¨æœ¬åœ°å¼€å¯ä»£ç†.png]]

### Cookie

[2.1.5_Cookie.py](https://github.com/LiuYuan-SHU/MyNotes/blob/master/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/2_use_of_basic_libraries/2.1/2.1.5_Cookie.py)

### `get_cookie`

æˆ‘ä»¬é¦–å…ˆåˆ›å»ºä¸€ä¸ªcookieå¯¹è±¡ï¼Œç„¶åå°†è¿™ä¸ªç©ºçš„cookieä¼ é€’ç»™ç½‘ç«™ï¼Œç½‘ç«™å°±ä¼šå°†æ–°çš„cookieå†™å…¥è¿™ä¸ªå¯¹è±¡ä¸­ã€‚æˆ‘ä»¬éå†è¿™ä¸ªå¯¹è±¡ï¼Œå°±èƒ½å¾—åˆ°ç½‘ç«™çš„cookie

### `save_cookie_in_Mozilla`&`save_cookie_in_LWP`

æ—¢ç„¶æˆ‘ä»¬å¯ä»¥æ‹¿åˆ°cookieï¼Œé‚£ä¹ˆæˆ‘ä»¬å°±å¯ä»¥ç”¨ä¸€äº›æ–¹æ³•å°†è¿™ä¸ªå¯¹è±¡è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼çš„å†…å®¹ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`MozillaCookieJar`æ–¹æ³•å’Œ`LWPCokkieJar`æ–¹æ³•å°†cookieè½¬æ¢ä¸ºç›¸åº”çš„æ ¼å¼å¹¶ä¿å­˜åœ¨`filename`ä¸­ï¼Œæ–¹ä¾¿ä¸‹æ¬¡æäº¤

### `read_cookie`

æˆ‘ä»¬å¯ä»¥ä»æ—¢æœ‰çš„æ–‡æœ¬æ–‡ä»¶ä¸­è¯»å–cookieï¼Œå¹¶å°†å…¶ä½œä¸ºç½‘ç«™ä¿å­˜åœ¨æœ¬åœ°çš„cookieæäº¤ï¼Œç›¸å½“äº**æˆ‘ä»¬è‡ªå·±å‡†å¤‡å¥½äº†cookieï¼Œè¿™æ ·å°±å¯ä»¥åœ¨å°†æ¥è·³è¿‡ç½‘ç«™çš„ç™»å½•æ­¥éª¤ï¼Œæ‰¾åˆ°æˆ‘ä»¬ä¹‹å‰ç™»å½•çš„sessionï¼Œç„¶åç›´æ¥å¼€å§‹çˆ¬å–å·¥ä½œ**

## å¤„ç†å¼‚å¸¸

[2.1.6_å¤„ç†å¼‚å¸¸.py](https://github.com/LiuYuan-SHU/MyNotes/blob/master/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/2_use_of_basic_libraries/2.1/2.1.6_%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8.py)

ğŸ“Œ é€šè¿‡åˆç†åœ°æ•è·ä¸€åœºå¯ä»¥åšå‡ºæ›´å‡†ç¡®çš„å¼‚å¸¸åˆ¤æ–­ï¼Œä½¿ç¨‹åºæ›´åŠ ç¨³å¥

### URLError

**æ‰€æœ‰`request`æ¨¡å—äº§ç”Ÿçš„å¼‚å¸¸éƒ½å¯ä»¥é€šè¿‡è¿™ä¸ªå¼‚å¸¸æ•è·æ¥å¤„ç†ã€‚**å®ƒå…·æœ‰ä¸€ä¸ªå±æ€§`reason`ï¼Œèƒ½å¤Ÿè¿”å›é”™è¯¯çš„åŸå› ã€‚

### HTTPError

HTTPErroræ˜¯URLErrorçš„å­ç±»ï¼Œä¸“é—¨ç”¨æ¥å¤„ç†HTTPè¯·æ±‚é”™è¯¯ï¼Œä¾‹å¦‚è®¤è¯å¤±è´¥ç­‰ã€‚å®ƒæœ‰å¦‚ä¸‹3ä¸ªå±æ€§

1. `code`ï¼šè¿”å›HTTPçŠ¶æ€ç ï¼Œä¾‹å¦‚404ç­‰
2. `reason`ï¼šè¿”å›é”™è¯¯åŸå› 
3. `heade`ï¼šè¿”å›è¯·æ±‚å¤´

å½“ç„¶ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©å…ˆæ•è·å­ç±»å¼‚å¸¸ï¼Œç„¶åå†æ•è·çˆ¶ç±»å¼‚å¸¸

---

æœ‰çš„æ—¶å€™è¿”å›çš„å¼‚å¸¸ä¸ä¸€å®šæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ä¹Ÿæœ‰å¯èƒ½æ˜¯ä¸€ä¸ªå¯¹è±¡ã€‚æˆ‘ä»¬å¯ä»¥ç”¨`isinstance`æ¥è¿›è¡Œæ›´åŠ è¯¦ç»†çš„åˆ†æï¼Œç„¶ååšå‡ºæ›´å¥½çš„è§£å†³

## è§£æé“¾æ¥

> `parse`æ¨¡å—å®šä¹‰äº†å¤„ç†URLçš„æ ‡å‡†æ¥å£ï¼Œä¾‹å¦‚å®ç°URLå„éƒ¨åˆ†çš„æŠ½å–ã€åˆå¹¶ä»¥åŠé“¾æ¥è½¬æ¢ã€‚
> 

### urlparse

[2.1.7_urlparse.py](https://github.com/LiuYuan-SHU/MyNotes/blob/master/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/2_use_of_basic_libraries/2.1/2.1.7_urlparse.py)

urlparseæ–¹æ³•åœ¨è§£æURLæ—¶æœ‰ç‰¹å®šçš„åˆ†éš”ç¬¦ã€‚

```python
ParseResult(scheme='https', netloc='www.baidu.com', path='/index.html', params='user', query='id=5', fragment='commit')
```

#### **æ ‡å‡†é“¾æ¥æ ¼å¼**

```
scheme://netloc/path;params?query#fragment
```

ä¸€ä¸ªæ ‡å‡†çš„URLéƒ½ä¼šç¬¦åˆè¿™ä¸ªè§„åˆ™ï¼Œåˆ©ç”¨urlparseæ–¹æ³•å°±å¯ä»¥å°†å…¶æ‹†åˆ†å¼€æ¥

1. schemeï¼šåè®®
2. netlocï¼šåŸŸå
3. pathï¼šè®¿é—®è·¯å¾„
4. paramsï¼šå‚æ•°
5. queryï¼šæŸ¥è¯¢æ¡ä»¶ï¼Œä¸€èˆ¬ç”¨ä½œGETç±»å‹çš„URL
6. fragmentï¼šé”šç‚¹ï¼Œç”¨äºç›´æ¥å®šä½é¡µé¢å†…éƒ¨çš„ä¸‹æ‹‰ä½ç½®

#### urlparse API

```python
urllib.parse.urlparse(urlstring, schme='', allow_fragments=True)
```

1. urlstringï¼šå¾…è§£æçš„URL
2. schemeï¼šå¦‚æœå¾…è§£æçš„URLæ²¡æœ‰å¸¦åè®®ä¿¡æ¯ï¼Œé‚£ä¹ˆå°±ä¼šæŠŠè¿™ä¸ªä½œä¸ºé»˜è®¤åè®®
3. allow_fragmentsï¼šæ˜¯å¦å¿½ç•¥`fragment`ã€‚å¦‚æœæ­¤é¡¹è¢«è®¾ç½®ä¸ºfalseï¼Œé‚£ä¹ˆfragmentéƒ¨åˆ†å°±ä¼šè¢«å¿½ç•¥ï¼Œå®ƒä¼šè¢«è§£æä¸ºpathï¼Œparamsæˆ–è€…queryçš„ä¸€éƒ¨åˆ†ï¼Œè€Œfragmentéƒ¨åˆ†ä¸ºç©º

è¿”å›çš„`ParseResult`å…¶å®æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œæ—¢å¯ä»¥ç”¨å±æ€§åè·å–å†…å®¹ï¼Œä¹Ÿå¯ä»¥ç”¨ç´¢å¼•æ¥é¡ºåºè·å–

```python
result.scheme # result[0]
result.netloc # result[1]
```

äºŒè€…æ˜¯ä¸€ä¸ªä¸œè¥¿

### urlunparse

[2.1.8_urlunparse.py](https://github.com/LiuYuan-SHU/MyNotes/blob/master/Crawler%20with%20Python3/Python3%20web%20crawler%20development%20practice%EF%BC%88Edition2%EF%BC%89%20-%20Cui%20Qingcai/2_use_of_basic_libraries/2.1/2.1.8_urlunparse.py)

`urlparse`ç”¨äºè§£æURLï¼Œ`urlunparse`ç”¨äºæ„é€ URLã€‚è¿™ä¸ªæ–¹æ³•æ¥æ”¶çš„å‚æ•°å¿…é¡»æ˜¯ä¸€ä¸ª**å¯è¿­ä»£å¯¹è±¡**ï¼Œå…¶é•¿åº¦**å¿…é¡»æ˜¯6**ã€‚

### urlsplit

è¿™ä¸ªæ–¹æ³•å’Œ`urlparse`éå¸¸ç±»ä¼¼ï¼Œä½†æ˜¯å®ƒä¸åœ¨å•ç‹¬è§£æ`params`è¿™ä¸€éƒ¨åˆ†ï¼Œè€Œæ˜¯ç›´æ¥åˆå¹¶åˆ°`path`ä¸­ï¼Œåªè¿”å›5ä¸ªç»“æœ

### urlunsplit

ä¸`urlunparse`ç±»ä¼¼ï¼Œåªæ˜¯åªèƒ½ä¼ å…¥ä¸€ä¸ªé•¿åº¦ä¸º5çš„å¯è¿­ä»£å¯¹è±¡

### urljoin

å‰é¢ä»‹ç»çš„ä¸¤ç§ç”¨äºæ„é€ URLçš„æ–¹æ³•çš„å‰æå°±æ˜¯å¿…é¡»ä¼ å…¥ç‰¹å®šé•¿åº¦çš„å¯¹è±¡ï¼Œé“¾æ¥çš„æ¯ä¸€ä¸ªéƒ¨åˆ†éƒ½å¿…é¡»æ¸…æ™°åˆ†å¼€ã€‚

é™¤äº†è¿™ä¸¤ç§æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`urljoin`ã€‚æˆ‘ä»¬å¯ä»¥æä¾›ä¸€ä¸ª`base_url`ä½œä¸ºç¬¬ä¸€å‚æ•°ï¼Œå°†æ–°çš„é“¾æ¥ä½œä¸ºç¬¬äºŒå‚æ•°ï¼Œæ–¹æ³•ä¼šåˆ†æç¬¬ä¸€å‚æ•°ä¸­çš„scheme, netlocå’Œpathè¿™ä¸‰ä¸ªå†…å®¹ï¼Œå¯¹æ–°é“¾æ¥ç¼ºå¤±çš„éƒ¨åˆ†è¿›è¡Œè¡¥å……ï¼Œæœ€åè¿”å›ç»“æœã€‚

å¦‚æœ`base_url`ä¸­æä¾›çš„ä¸‰ä¸ªå‚æ•°åœ¨æ–°é“¾æ¥ä¸­å·²ç»å­˜åœ¨ï¼Œé‚£ä¹ˆä¸ä¼šè¿›è¡Œè¡¥å……ã€‚å¦åˆ™æ‰è¿›è¡Œè¡¥å……

### urlencode

è¿™ä¸ªæ–¹æ³•åœ¨æ„é€ GETè¯·æ±‚çš„æ—¶å€™éå¸¸æœ‰ç”¨ã€‚

```python
params = {
	'name': 'germey',
	'age': 25
}
base_url = 'https://www.baidu.com'
url = base_url + urlencode(params)
print(url)
```

è¿™æ ·å°±å¯ä»¥å°†ä¸€ä¸ªå­—å…¸ä¸­çš„å†…å®¹è½¬åŒ–ä¸ºURLä¸­çš„GETè¯·æ±‚å‚æ•°

### parse_qs

æœ‰åºåˆ—åŒ–ï¼Œè‡ªç„¶å°±ä¼šæœ‰ååºåˆ—åŒ–ï¼Œé€šè¿‡è¿™ä¸ªæ–¹æ³•ï¼Œå°±å¯ä»¥å°†ä¸€ä¸ªURLä¸­çš„GETå‚æ•°è½¬æ¢ä¸ºå­—å…¸

### parse_qsl

è¿™ä¸ªæ–¹æ³•ç”¨äºå°†å‚æ•°è½¬åŒ–ä¸ºç”±å…ƒç»„ç»„æˆçš„åˆ—è¡¨

### quote

ç”¨è¿™ä¸ªæ–¹æ³•å¯ä»¥å°†å†…å®¹è½¬åŒ–ä¸ºURLç¼–ç æ ¼å¼ï¼Œä¸»è¦ç”¨äºè½¬æ¢ä¸­æ–‡å‚æ•°

```python
keyword = 'å£çº¸'
url = 'https://www.baidu.com/s?wd=' + quote(keyword)
print(url)
```

### unquote

è¿›è¡ŒURLè§£ç 
